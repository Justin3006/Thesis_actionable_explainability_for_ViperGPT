- TCL_M4 moved to different address, now only available in archive with different models. 
  => Use this call:   
        gdown "https://drive.google.com/uc?id=1eHinvFP7TnZYAL2Ft-M8rPott7mpVN2R" -O TCL.zip
     then unzip TCL.zip

- Issues with importing BLIP-2 from transformers 
  => pip install transformers==4.27.0
- Required for compatibility: 
  - Use new torch versions
  - pip install -U accelerate
  - pip install -U bitsandbytes
  - pip install -U inflect
- In torchvision add NEAREST_EXACT = "nearest" to InterpolationMode in transforms.functional.py
- In transformers.models.blip_2.modeling_blip2: from ...generation import GenerationMixin => from ...generation.utils import GenerationMixin

- execute:
     export TORCH_HOME='<INSERT_SOME_PATH_HERE>/TORCH_HOME'
     export HF_HOME='<INSERT_SOME_PATH_HERE>/HF_HOME'

- upgrade protobuff, copy builder, downgrade to 3.19.6, paste builder 
- in /GLIP/maskrcnn_benchmark/csrc/cuda/: Change all 'AT_DISPATCH_FLOATING_TYPES({X}.type()' references to 'AT_DISPATCH_FLOATING_TYPES({X}.scalar_type()'

- in python execute:
     import nltk
     nltk.download('punkt', download_dir=<INSERT_SOME_PATH_HERE>)
     nltk.download('averaged_perceptron_tagger', download_dir=<INSERT_SOME_PATH_HERE>)
